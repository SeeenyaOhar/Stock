{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import sys\n",
    "import keras\n",
    "sys.path.append(\"D:\\\\documents\\\\code\\\\stock\\\\NNS\\\\feedback_classifier\\\\dataset\")\n",
    "sys.path.append(\"D:\\\\documents\\\\code\\\\stock\\\\NNS\\\\inquiryProcessor\")\n",
    "sys.path.append(\"D:\\\\documents\\\\code\\\\stock\\\\NNS\\\\feedback_classifier\")\n",
    "sys.path.append(\"D:\\\\documents\\\\code\\\\stock\\\\NNS\")\n",
    "sys.path.append(\"D:\\\\documents\\\\code\\\\stock\")\n",
    "from model import FeedbackClassifier, FeedbackClassifierBERT, FeedbackClassifierBERTModel\n",
    "from dataset import FeedbackDataset\n",
    "from NNS.inquiryProcessor.bert import get_bert_details"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_ds(BATCH_SIZE: int, dataset_path: str):\n",
    "    npdataset = FeedbackDataset.get_ds(dataset_path)\n",
    "    train_examples = tf.convert_to_tensor(npdataset[:, 0], dtype=tf.string)\n",
    "    train_labels = np.stack(npdataset[:, 1])\n",
    "    assert len(train_labels.shape) == 1\n",
    "    train_labels = train_labels.reshape((npdataset[:, 1].shape[0], 1))  # tensorflow can't convert labels easily\n",
    "    train_labels = tf.convert_to_tensor(train_labels, dtype=tf.int32)\n",
    "    dataset = tf.data.Dataset.from_tensor_slices((train_examples, train_labels))\n",
    "    train_ds = dataset.batch(BATCH_SIZE, drop_remainder=False).cache().prefetch(buffer_size=tf.data.AUTOTUNE)\n",
    "    return train_ds\n",
    "\n",
    "\n",
    "def train(savepath, epochs=100, model: keras.Model=None):\n",
    "    # assert(type(savepath) == str and callback == None or type(callback) == keras.callbacks.ModelCheckpoint)\n",
    "    BATCH_SIZE = 32\n",
    "    # lets get the dataset first\n",
    "    train_ds = get_ds(BATCH_SIZE, \"D:\\\\documents\\\\code\\\\stock\\\\NNS\\\\feedback_classifier\\\\dataset\\\\feedback.csv\", ) # TODO: TYPE IN YOUR GIT PATH\n",
    "    print(train_ds)\n",
    "    # TODO: SOLVE THIS LOCAL PATH PROBLEM\n",
    "    if model == None:\n",
    "        tfhub_handle_preprocess, tfhub_handle_encoder = get_bert_details()\n",
    "        model = FeedbackClassifierBERTModel(tfhub_handle_preprocess, tfhub_handle_encoder)\n",
    "    analyzer = FeedbackClassifierBERT(model)\n",
    "    logs = analyzer.train(ds=train_ds, epochs=epochs)\n",
    "    model.save(savepath, save_format=\"tf\")  # creates a folder inside NNS/InquiryProcessor\\\n",
    "    return logs\n",
    "\n",
    "\n",
    "def get_model_from_file(filepath, ds: tf.data.Dataset, epochs: int):\n",
    "    model = keras.models.load_model(filepath, custom_objects={\"AdamWeightDecay\": FeedbackClassifierBERT.get_optimizer(ds, epochs)})\n",
    "    return model\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading content from D:\\documents\\code\\stock\\NNS\\feedback_classifier\\dataset\\feedback.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\documents\\code\\stock\\NNS\\feedback_classifier\\dataset\\dataset.py:21: FutureWarning: The warn_bad_lines argument has been deprecated and will be removed in a future version. Use on_bad_lines in the future.\n",
      "\n",
      "\n",
      "  dataset = pd.read_csv(filepath, warn_bad_lines=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(<tf.Tensor: shape=(), dtype=int64, numpy=0>, (<tf.Tensor: shape=(13,), dtype=string, numpy=\n",
      "array([b\"Hey, thank you for the new item. It's lit!!!\",\n",
      "       b'Thank you for the pizza! The quality is above the sky!',\n",
      "       b'The pizza is lit! Thank a lot!',\n",
      "       b\"Why do you deliver them in plastic packaging! It's bad for the environment! Replace those with organic stuff!\",\n",
      "       b'The pizza stinks as shit! What the hell is this????',\n",
      "       b'Why the hell did you put the tomatoes inside!? I told you not to put them!',\n",
      "       b\"I've already taken them from the post office! They're so soft and sweet! Thank you and love you!\",\n",
      "       b'I like everything except the price. Could be a bit cheaper. Everything else is great!',\n",
      "       b'The delivery took a bit long but nothing bad happened then. The shoes are great. Pull them on every day, no problem.',\n",
      "       b\"No comment! They're amazing!\", b'Jesus, thank you! So awesome!',\n",
      "       b'Oh, God, thanks a lot! Ur awesome guys, thank you!!!',\n",
      "       b'Oh yeah, everything is great. Everything is awesome!'],\n",
      "      dtype=object)>, <tf.Tensor: shape=(13, 1), dtype=int32, numpy=\n",
      "array([[1],\n",
      "       [1],\n",
      "       [1],\n",
      "       [0],\n",
      "       [0],\n",
      "       [0],\n",
      "       [1],\n",
      "       [1],\n",
      "       [1],\n",
      "       [1],\n",
      "       [1],\n",
      "       [1],\n",
      "       [1]])>))\n"
     ]
    }
   ],
   "source": [
    "ds = get_ds(32, \"D:\\\\documents\\\\code\\\\stock\\\\NNS\\\\feedback_classifier\\\\dataset\\\\feedback.csv\")\n",
    "for i in ds.enumerate():\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading content from D:\\documents\\code\\stock\\NNS\\feedback_classifier\\dataset\\feedback.csv\n",
      "<PrefetchDataset shapes: ((None,), (None, 1)), types: (tf.string, tf.int32)>\n",
      "BERT model selected           : https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-4_H-512_A-8/1\n",
      "Preprocess model auto-selected: https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\documents\\code\\stock\\NNS\\feedback_classifier\\dataset\\dataset.py:21: FutureWarning: The warn_bad_lines argument has been deprecated and will be removed in a future version. Use on_bad_lines in the future.\n",
      "\n",
      "\n",
      "  dataset = pd.read_csv(filepath, warn_bad_lines=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "in user code:\n\n    File \"d:\\SOFT\\anaconda\\envs\\Stock\\lib\\site-packages\\keras\\engine\\training.py\", line 878, in train_function  *\n        return step_function(self, iterator)\n    File \"d:\\SOFT\\anaconda\\envs\\Stock\\lib\\site-packages\\keras\\engine\\training.py\", line 867, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"d:\\SOFT\\anaconda\\envs\\Stock\\lib\\site-packages\\keras\\engine\\training.py\", line 860, in run_step  **\n        outputs = model.train_step(data)\n    File \"d:\\SOFT\\anaconda\\envs\\Stock\\lib\\site-packages\\keras\\engine\\training.py\", line 808, in train_step\n        y_pred = self(x, training=True)\n    File \"d:\\SOFT\\anaconda\\envs\\Stock\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 67, in error_handler\n        raise e.with_traceback(filtered_tb) from None\n\n    ValueError: Exception encountered when calling layer \"feedback_classifier_bert_model\" (type FeedbackClassifierBERTModel).\n    \n    in user code:\n    \n        File \"d:\\documents\\code\\stock\\NNS\\feedback_classifier\\BERT\\model.py\", line 20, in call  *\n            y = self.encoder(x)['pooled_output']\n        File \"d:\\SOFT\\anaconda\\envs\\Stock\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 67, in error_handler  **\n            raise e.with_traceback(filtered_tb) from None\n    \n        ValueError: Exception encountered when calling layer \"ENCODER_LAYER\" (type KerasLayer).\n        \n        in user code:\n        \n            File \"d:\\SOFT\\anaconda\\envs\\Stock\\lib\\site-packages\\tensorflow_hub\\keras_layer.py\", line 229, in call  *\n                result = smart_cond.smart_cond(training,\n        \n            ValueError: Could not find matching concrete function to call loaded from the SavedModel. Got:\n              Positional arguments (3 total):\n                * Tensor(\"inputs:0\", shape=(None,), dtype=string)\n                * False\n                * None\n              Keyword arguments: {}\n            \n             Expected these arguments to match one of the following 4 option(s):\n            \n            Option 1:\n              Positional arguments (3 total):\n                * {'input_type_ids': TensorSpec(shape=(None, None), dtype=tf.int32, name='inputs/input_type_ids'), 'input_word_ids': TensorSpec(shape=(None, None), dtype=tf.int32, name='inputs/input_word_ids'), 'input_mask': TensorSpec(shape=(None, None), dtype=tf.int32, name='inputs/input_mask')}\n                * False\n                * None\n              Keyword arguments: {}\n            \n            Option 2:\n              Positional arguments (3 total):\n                * {'input_mask': TensorSpec(shape=(None, None), dtype=tf.int32, name='input_mask'), 'input_type_ids': TensorSpec(shape=(None, None), dtype=tf.int32, name='input_type_ids'), 'input_word_ids': TensorSpec(shape=(None, None), dtype=tf.int32, name='input_word_ids')}\n                * True\n                * None\n              Keyword arguments: {}\n            \n            Option 3:\n              Positional arguments (3 total):\n                * {'input_type_ids': TensorSpec(shape=(None, None), dtype=tf.int32, name='inputs/input_type_ids'), 'input_mask': TensorSpec(shape=(None, None), dtype=tf.int32, name='inputs/input_mask'), 'input_word_ids': TensorSpec(shape=(None, None), dtype=tf.int32, name='inputs/input_word_ids')}\n                * True\n                * None\n              Keyword arguments: {}\n            \n            Option 4:\n              Positional arguments (3 total):\n                * {'input_word_ids': TensorSpec(shape=(None, None), dtype=tf.int32, name='input_word_ids'), 'input_mask': TensorSpec(shape=(None, None), dtype=tf.int32, name='input_mask'), 'input_type_ids': TensorSpec(shape=(None, None), dtype=tf.int32, name='input_type_ids')}\n                * False\n                * None\n              Keyword arguments: {}\n        \n        \n        Call arguments received:\n          • inputs=tf.Tensor(shape=(None,), dtype=string)\n          • training=True\n    \n    \n    Call arguments received:\n      • x=tf.Tensor(shape=(None,), dtype=string)\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32md:\\documents\\code\\stock\\NNS\\feedback_classifier\\BERT\\notebook.ipynb Cell 4'\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/documents/code/stock/NNS/feedback_classifier/BERT/notebook.ipynb#ch0000003?line=0'>1</a>\u001b[0m savepath \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mD:\u001b[39m\u001b[39m\\\\\u001b[39;00m\u001b[39mdocuments\u001b[39m\u001b[39m\\\\\u001b[39;00m\u001b[39mcode\u001b[39m\u001b[39m\\\\\u001b[39;00m\u001b[39mstock\u001b[39m\u001b[39m\\\\\u001b[39;00m\u001b[39mNNS\u001b[39m\u001b[39m\\\\\u001b[39;00m\u001b[39mfeedback_classifier\u001b[39m\u001b[39m\\\\\u001b[39;00m\u001b[39mBERT\u001b[39m\u001b[39m\\\\\u001b[39;00m\u001b[39mfeedback_model\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/d%3A/documents/code/stock/NNS/feedback_classifier/BERT/notebook.ipynb#ch0000003?line=1'>2</a>\u001b[0m train(savepath)\n",
      "\u001b[1;32md:\\documents\\code\\stock\\NNS\\feedback_classifier\\BERT\\notebook.ipynb Cell 2'\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(savepath, epochs, model)\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/documents/code/stock/NNS/feedback_classifier/BERT/notebook.ipynb#ch0000001?line=21'>22</a>\u001b[0m     model \u001b[39m=\u001b[39m FeedbackClassifierBERTModel(tfhub_handle_preprocess, tfhub_handle_encoder)\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/documents/code/stock/NNS/feedback_classifier/BERT/notebook.ipynb#ch0000001?line=22'>23</a>\u001b[0m analyzer \u001b[39m=\u001b[39m FeedbackClassifierBERT(model)\n\u001b[1;32m---> <a href='vscode-notebook-cell:/d%3A/documents/code/stock/NNS/feedback_classifier/BERT/notebook.ipynb#ch0000001?line=23'>24</a>\u001b[0m logs \u001b[39m=\u001b[39m analyzer\u001b[39m.\u001b[39;49mtrain(ds\u001b[39m=\u001b[39;49mtrain_ds, epochs\u001b[39m=\u001b[39;49mepochs)\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/documents/code/stock/NNS/feedback_classifier/BERT/notebook.ipynb#ch0000001?line=24'>25</a>\u001b[0m model\u001b[39m.\u001b[39msave(savepath, save_format\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mtf\u001b[39m\u001b[39m\"\u001b[39m)  \u001b[39m# creates a folder inside NNS/InquiryProcessor\\\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/documents/code/stock/NNS/feedback_classifier/BERT/notebook.ipynb#ch0000001?line=25'>26</a>\u001b[0m \u001b[39mreturn\u001b[39;00m logs\n",
      "File \u001b[1;32md:\\documents\\code\\stock\\NNS\\feedback_classifier\\BERT\\model.py:62\u001b[0m, in \u001b[0;36mFeedbackClassifierBERT.train\u001b[1;34m(self, ds, epochs)\u001b[0m\n\u001b[0;32m     <a href='file:///d%3A/documents/code/stock/NNS/feedback_classifier/BERT/model.py?line=59'>60</a>\u001b[0m metrics \u001b[39m=\u001b[39m FeedbackClassifierBERT\u001b[39m.\u001b[39mget_metrics()\n\u001b[0;32m     <a href='file:///d%3A/documents/code/stock/NNS/feedback_classifier/BERT/model.py?line=60'>61</a>\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmodel\u001b[39m.\u001b[39mcompile(optimizer\u001b[39m=\u001b[39moptimizer, loss\u001b[39m=\u001b[39mloss, metrics\u001b[39m=\u001b[39mmetrics)\n\u001b[1;32m---> <a href='file:///d%3A/documents/code/stock/NNS/feedback_classifier/BERT/model.py?line=61'>62</a>\u001b[0m logs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmodel\u001b[39m.\u001b[39;49mfit(x\u001b[39m=\u001b[39;49mds, epochs\u001b[39m=\u001b[39;49mepochs)\n\u001b[0;32m     <a href='file:///d%3A/documents/code/stock/NNS/feedback_classifier/BERT/model.py?line=62'>63</a>\u001b[0m \u001b[39mreturn\u001b[39;00m logs\n",
      "File \u001b[1;32md:\\SOFT\\anaconda\\envs\\Stock\\lib\\site-packages\\keras\\utils\\traceback_utils.py:67\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     <a href='file:///d%3A/SOFT/anaconda/envs/Stock/lib/site-packages/keras/utils/traceback_utils.py?line=64'>65</a>\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:  \u001b[39m# pylint: disable=broad-except\u001b[39;00m\n\u001b[0;32m     <a href='file:///d%3A/SOFT/anaconda/envs/Stock/lib/site-packages/keras/utils/traceback_utils.py?line=65'>66</a>\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n\u001b[1;32m---> <a href='file:///d%3A/SOFT/anaconda/envs/Stock/lib/site-packages/keras/utils/traceback_utils.py?line=66'>67</a>\u001b[0m   \u001b[39mraise\u001b[39;00m e\u001b[39m.\u001b[39mwith_traceback(filtered_tb) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39m\n\u001b[0;32m     <a href='file:///d%3A/SOFT/anaconda/envs/Stock/lib/site-packages/keras/utils/traceback_utils.py?line=67'>68</a>\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[0;32m     <a href='file:///d%3A/SOFT/anaconda/envs/Stock/lib/site-packages/keras/utils/traceback_utils.py?line=68'>69</a>\u001b[0m   \u001b[39mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32md:\\SOFT\\anaconda\\envs\\Stock\\lib\\site-packages\\tensorflow\\python\\framework\\func_graph.py:1129\u001b[0m, in \u001b[0;36mfunc_graph_from_py_func.<locals>.autograph_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m   <a href='file:///d%3A/SOFT/anaconda/envs/Stock/lib/site-packages/tensorflow/python/framework/func_graph.py?line=1126'>1127</a>\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:  \u001b[39m# pylint:disable=broad-except\u001b[39;00m\n\u001b[0;32m   <a href='file:///d%3A/SOFT/anaconda/envs/Stock/lib/site-packages/tensorflow/python/framework/func_graph.py?line=1127'>1128</a>\u001b[0m   \u001b[39mif\u001b[39;00m \u001b[39mhasattr\u001b[39m(e, \u001b[39m\"\u001b[39m\u001b[39mag_error_metadata\u001b[39m\u001b[39m\"\u001b[39m):\n\u001b[1;32m-> <a href='file:///d%3A/SOFT/anaconda/envs/Stock/lib/site-packages/tensorflow/python/framework/func_graph.py?line=1128'>1129</a>\u001b[0m     \u001b[39mraise\u001b[39;00m e\u001b[39m.\u001b[39mag_error_metadata\u001b[39m.\u001b[39mto_exception(e)\n\u001b[0;32m   <a href='file:///d%3A/SOFT/anaconda/envs/Stock/lib/site-packages/tensorflow/python/framework/func_graph.py?line=1129'>1130</a>\u001b[0m   \u001b[39melse\u001b[39;00m:\n\u001b[0;32m   <a href='file:///d%3A/SOFT/anaconda/envs/Stock/lib/site-packages/tensorflow/python/framework/func_graph.py?line=1130'>1131</a>\u001b[0m     \u001b[39mraise\u001b[39;00m\n",
      "\u001b[1;31mValueError\u001b[0m: in user code:\n\n    File \"d:\\SOFT\\anaconda\\envs\\Stock\\lib\\site-packages\\keras\\engine\\training.py\", line 878, in train_function  *\n        return step_function(self, iterator)\n    File \"d:\\SOFT\\anaconda\\envs\\Stock\\lib\\site-packages\\keras\\engine\\training.py\", line 867, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"d:\\SOFT\\anaconda\\envs\\Stock\\lib\\site-packages\\keras\\engine\\training.py\", line 860, in run_step  **\n        outputs = model.train_step(data)\n    File \"d:\\SOFT\\anaconda\\envs\\Stock\\lib\\site-packages\\keras\\engine\\training.py\", line 808, in train_step\n        y_pred = self(x, training=True)\n    File \"d:\\SOFT\\anaconda\\envs\\Stock\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 67, in error_handler\n        raise e.with_traceback(filtered_tb) from None\n\n    ValueError: Exception encountered when calling layer \"feedback_classifier_bert_model\" (type FeedbackClassifierBERTModel).\n    \n    in user code:\n    \n        File \"d:\\documents\\code\\stock\\NNS\\feedback_classifier\\BERT\\model.py\", line 20, in call  *\n            y = self.encoder(x)['pooled_output']\n        File \"d:\\SOFT\\anaconda\\envs\\Stock\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 67, in error_handler  **\n            raise e.with_traceback(filtered_tb) from None\n    \n        ValueError: Exception encountered when calling layer \"ENCODER_LAYER\" (type KerasLayer).\n        \n        in user code:\n        \n            File \"d:\\SOFT\\anaconda\\envs\\Stock\\lib\\site-packages\\tensorflow_hub\\keras_layer.py\", line 229, in call  *\n                result = smart_cond.smart_cond(training,\n        \n            ValueError: Could not find matching concrete function to call loaded from the SavedModel. Got:\n              Positional arguments (3 total):\n                * Tensor(\"inputs:0\", shape=(None,), dtype=string)\n                * False\n                * None\n              Keyword arguments: {}\n            \n             Expected these arguments to match one of the following 4 option(s):\n            \n            Option 1:\n              Positional arguments (3 total):\n                * {'input_type_ids': TensorSpec(shape=(None, None), dtype=tf.int32, name='inputs/input_type_ids'), 'input_word_ids': TensorSpec(shape=(None, None), dtype=tf.int32, name='inputs/input_word_ids'), 'input_mask': TensorSpec(shape=(None, None), dtype=tf.int32, name='inputs/input_mask')}\n                * False\n                * None\n              Keyword arguments: {}\n            \n            Option 2:\n              Positional arguments (3 total):\n                * {'input_mask': TensorSpec(shape=(None, None), dtype=tf.int32, name='input_mask'), 'input_type_ids': TensorSpec(shape=(None, None), dtype=tf.int32, name='input_type_ids'), 'input_word_ids': TensorSpec(shape=(None, None), dtype=tf.int32, name='input_word_ids')}\n                * True\n                * None\n              Keyword arguments: {}\n            \n            Option 3:\n              Positional arguments (3 total):\n                * {'input_type_ids': TensorSpec(shape=(None, None), dtype=tf.int32, name='inputs/input_type_ids'), 'input_mask': TensorSpec(shape=(None, None), dtype=tf.int32, name='inputs/input_mask'), 'input_word_ids': TensorSpec(shape=(None, None), dtype=tf.int32, name='inputs/input_word_ids')}\n                * True\n                * None\n              Keyword arguments: {}\n            \n            Option 4:\n              Positional arguments (3 total):\n                * {'input_word_ids': TensorSpec(shape=(None, None), dtype=tf.int32, name='input_word_ids'), 'input_mask': TensorSpec(shape=(None, None), dtype=tf.int32, name='input_mask'), 'input_type_ids': TensorSpec(shape=(None, None), dtype=tf.int32, name='input_type_ids')}\n                * False\n                * None\n              Keyword arguments: {}\n        \n        \n        Call arguments received:\n          • inputs=tf.Tensor(shape=(None,), dtype=string)\n          • training=True\n    \n    \n    Call arguments received:\n      • x=tf.Tensor(shape=(None,), dtype=string)\n"
     ]
    }
   ],
   "source": [
    "savepath = \"D:\\\\documents\\\\code\\\\stock\\\\NNS\\\\feedback_classifier\\\\BERT\\\\feedback_model\"\n",
    "train(savepath)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "1f716af3f83aa1e776ab5faf5a7bcecc5e1fe6e401a6591d6c367882f206c492"
  },
  "kernelspec": {
   "display_name": "Python 3.9.12 ('Stock')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
