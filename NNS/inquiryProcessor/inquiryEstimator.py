# Logicimport torchimport torch.nn as nnimport torch.nn.functional as Fimport torch.optim as optimimport torch.nn.utils.rnn as utilsimport numpy as npimport time# UIimport curses as cursesimport matplotlib.pyplot as pltclass InquiryDataset:    """    Manages the training datasets.    """    contact = np.array([0, 1, 0, 0, 0, 0, 0, 0, 0, 0])    dataset_search = np.array([0, 0, 1, 0, 0, 0, 0, 0, 0, 0])    delivery = np.array([0, 0, 0, 1, 0, 0, 0, 0, 0, 0])    user_interaction_needed = np.array([1, 0, 0, 0, 0, 0, 0, 0, 0, 0])    order = np.array([0, 0, 0, 0, 1, 0, 0, 0, 0, 0])    @staticmethod    def getTrainingDataset() -> np.ndarray:        """        Returns a training dataset [19, 2] that contains inquiries and classifications respectively.        :return: Returns a numpy array [19, 2] with inquiries and classifications        """        return np.array([["Hi, what's your phone number?", InquiryDataset.contact],                         ["Hi, may I get the phone number?", InquiryDataset.contact],                         ["Hi, I want to order this product", (InquiryDataset.order + InquiryDataset.dataset_search), ],                         ["Good morning, I'm interested in this product. What's the price of this one?",                          InquiryDataset.dataset_search],                         ["Are there any of this product in stock?", InquiryDataset.dataset_search],                         ["What are the ways to deliver the product?", InquiryDataset.delivery],                         ["How long does the delivery take?", InquiryDataset.delivery],                         ["Are any of this product available?", InquiryDataset.dataset_search],                         ["What about the delivery?", InquiryDataset.delivery],                         ["Does it have this characteristic?", InquiryDataset.user_interaction_needed],                         ["We want to cooperate with your company.", InquiryDataset.user_interaction_needed],                         ["We would be glad to work with your company indeed.", InquiryDataset.user_interaction_needed],                         ["Hi, name, is that you?", InquiryDataset.user_interaction_needed],                         ["Is the delivery available to Ukraine?", InquiryDataset.delivery],                         ["Is the delivery available to this country?", InquiryDataset.delivery],                         ["What's the price of the delivery?", InquiryDataset.delivery],                         ["May I pay for the this product when I receive it?", InquiryDataset.delivery],                         ["What is included in the set?", InquiryDataset.dataset_search],                         ["What is included with the product?", InquiryDataset.dataset_search]])class InquiryAnalyzer(nn.Module):    """    Basically, neural network that classifies the inquiry embeddings based on the context.    """    # Initializing model here    def __init__(self, terminalUI=False):        # init the super of pytorch neural network        super(InquiryAnalyzer, self).__init__()        # Shrinking down the data        # Or in other words cutting down the data we don't need        if terminalUI:            self.epochScr = curses.initscr()        self.l1 = torch.nn.Linear(300, 100)        self.l2 = torch.nn.Linear(100, 50)        self.lstm = torch.nn.LSTM(50, 20, 10)        self.softmax = torch.nn.Linear(20, 10)    def forward(self, x, cellStateSize=1):        """        Forward propogation.        :param x: Tensor of words [1, 300]        :return: Tensor [?, 1, 10] with the inquiry classifications.        """        assert (isinstance(x, torch.nn.utils.rnn.PackedSequence))        # x here is the inquiry        cell_state = torch.zeros(10, cellStateSize, 20, dtype=torch.double)  # check the correctness of the size        hidden_state = torch.zeros(10, cellStateSize, 20, dtype=torch.double)  # check the correctness of the size        # Checking if all of the elements of array x(which is an inquiry basically)        result = None        # going through every word        if x.data[0].shape[0] != 300:            raise ValueError("The size of x has to be 300(vector features of the word)")        else:            currentInput = x            # (1) Densed layer(shrinking down)            currentInput = PackedSequenceHelper.squash_packed(currentInput, self.l1)            currentInput = PackedSequenceLeakyReluHelper.squash_packed_relu(currentInput, )            # (2) Densed layer(shrinking down even more)            currentInput = PackedSequenceHelper.squash_packed(currentInput, self.l2)            currentInput = PackedSequenceLeakyReluHelper.squash_packed_relu(currentInput)            # (3) LSTM Layer - based on the hidden state and cell state we predict what does the sentence mean            # In other words, what kind of inquiry user has made            (out, h0) = self.lstm(currentInput, (hidden_state, cell_state))            result = out            hidden_state = h0        # (4) - Softmax layer(output layer) | Classifying the inquiry        result = PackedSequenceHelper.squash_packed(result, self.softmax)        result = PackedSequenceHelper.squash_packed_softmax(result, dim=1)        return self._sequenceLabels(result)    def trainData(self, x, y, epochs=1000):        """        Trains the data over a sequence. Uses the MSE Loss.        :param x:        :param y:        :param epochs:        :return: List of loss values        """        assert (isinstance(x, torch.nn.utils.rnn.PackedSequence))        assert (isinstance(y, torch.Tensor))        # assert(isinstance(y, torch.Tensor))        # assert(isinstance(epochs, int))        # optimizer = optim.SGD(self.parameters(), lr=0.01, momentum=0.9)        optimizer = optim.Adam(self.parameters())        error = torch.nn.MSELoss()        losses = []        for i in range(epochs):            self._changeEpoch(i)            # batchSize = 0            # dataBatchStartIndex = 0            # for n in x.batch_sizes:            #     batchSize = n            #     dataBatchEnd = dataBatchStartIndex + batchSize            #     currentBatch = x.data[dataBatchStartIndex:dataBatchEnd]            output = self.forward(x, cellStateSize=len(x.sorted_indices))            loss_value = error(output, y)            self._changeAccuracy(loss_value)            loss_value.backward()            optimizer.step()            losses.append(loss_value)        optimizer.zero_grad()        output = self.forward(x, cellStateSize=len(x.sorted_indices))        loss_value = error(output, y)        self._changeAccuracy(loss_value)        loss_value.backward()        optimizer.step()        self.epochScr.erase()        print("Final result: {0}".format(output))        print("\nLoss: {0}".format(loss_value))        self.epochScr.refresh()        plt.plot(losses)        plt.ylabel("losses")        plt.show()    def _sequenceLabels(self, packed):        """        Returns a Tensor of labels from a packed sequence.        :param packed:        :return:        """        temp = utils.pad_packed_sequence(packed, batch_first=True)        padded = temp[0]        lengths = temp[1]        result = torch.zeros(len(padded), 10, dtype=torch.double)        for n, i in enumerate(padded):            curEl = padded[n, lengths[n] - 1]            result[n] = curEl        return result    def _changeEpoch(self, epoch):        """        Changes the epoch number to {epoch} in Terminal. Uses curses library.        :param epoch: Epoch number that the Terminal text has to changed to.        :return: None        """        self.epochScr.erase()        self.epochScr.addstr("Epoch: {0} \nAccuracy: ".format(epoch))        self.epochScr.refresh()        time.sleep(0.001)    def _changeAccuracy(self, accuracy):        """        Changes the accuracy to {accuracy} in Terminal. Uses curses library.        :param accuracy: Accuracy number.        :return: None        """        self.epochScr.addstr("{0}".format(accuracy))        self.epochScr.refresh()        time.sleep(0.001)class PackedSequenceHelper:    @staticmethod    def squash_packed(x, fn=torch.tanh):        """        Computes fn with an argument x.data, where x is PackedSequence.        :param x: PackedSequence that the function is processed with respect to its data.        :param fn: Function which we process.        :return: PackedSequence with the processed output of function fn with respect to x.data.        """        return torch.nn.utils.rnn.PackedSequence(fn(x.data), x.batch_sizes,                                                 x.sorted_indices, x.unsorted_indices)    @staticmethod    def squash_packed_softmax(x, dim=2):        """        Computes softmax with an argument x.data where x is PackedSequence        :param x: PackedSequence that the softmax is processed with respect to its data        :param dim: A dimension along which the softmax will be computed.        :return: A processed PackedSequence with softmax.        """        return torch.nn.utils.rnn.PackedSequence(F.softmax(x.data, dim), x.batch_sizes,                                                 x.sorted_indices, x.unsorted_indices)class PackedSequenceLeakyReluHelper:    @staticmethod    def squash_packed_relu(x, slope=0.1):        """        Squashes the PackedSequence with Leaky Relu Function.        :param x: The PackedSequence whose data we process with Leaky Relu.        :param slope: The slope number for softmax.        :return: Squashed PackedSequence.        """        return torch.nn.utils.rnn.PackedSequence(F.leaky_relu(x.data, negative_slope=slope), x.batch_sizes,                                                 x.sorted_indices, x.unsorted_indices)