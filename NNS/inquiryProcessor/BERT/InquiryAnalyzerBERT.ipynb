{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "import os\n",
    "\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"-1\"\n",
    "import shutil\n",
    "from typing import Tuple\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub\n",
    "import tensorflow.keras as keras\n",
    "import tensorflow_text as text\n",
    "from official.nlp import optimization  # to create AdamW optimizer\n",
    "from dataset import InquiryDataset\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "def get_bert_details():\n",
    "    \"\"\"\n",
    "    Returns handle encoder and bert model links.\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    bert_model_name = 'small_bert/bert_en_uncased_L-4_H-512_A-8'\n",
    "\n",
    "    map_name_to_handle = {\n",
    "        'bert_en_uncased_L-12_H-768_A-12':\n",
    "            'https://tfhub.dev/tensorflow/bert_en_uncased_L-12_H-768_A-12/3',\n",
    "        'bert_en_cased_L-12_H-768_A-12':\n",
    "            'https://tfhub.dev/tensorflow/bert_en_cased_L-12_H-768_A-12/3',\n",
    "        'bert_multi_cased_L-12_H-768_A-12':\n",
    "            'https://tfhub.dev/tensorflow/bert_multi_cased_L-12_H-768_A-12/3',\n",
    "        'small_bert/bert_en_uncased_L-2_H-128_A-2':\n",
    "            'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-2_H-128_A-2/1',\n",
    "        'small_bert/bert_en_uncased_L-2_H-256_A-4':\n",
    "            'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-2_H-256_A-4/1',\n",
    "        'small_bert/bert_en_uncased_L-2_H-512_A-8':\n",
    "            'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-2_H-512_A-8/1',\n",
    "        'small_bert/bert_en_uncased_L-2_H-768_A-12':\n",
    "            'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-2_H-768_A-12/1',\n",
    "        'small_bert/bert_en_uncased_L-4_H-128_A-2':\n",
    "            'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-4_H-128_A-2/1',\n",
    "        'small_bert/bert_en_uncased_L-4_H-256_A-4':\n",
    "            'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-4_H-256_A-4/1',\n",
    "        'small_bert/bert_en_uncased_L-4_H-512_A-8':\n",
    "            'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-4_H-512_A-8/1',\n",
    "        'small_bert/bert_en_uncased_L-4_H-768_A-12':\n",
    "            'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-4_H-768_A-12/1',\n",
    "        'small_bert/bert_en_uncased_L-6_H-128_A-2':\n",
    "            'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-6_H-128_A-2/1',\n",
    "        'small_bert/bert_en_uncased_L-6_H-256_A-4':\n",
    "            'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-6_H-256_A-4/1',\n",
    "        'small_bert/bert_en_uncased_L-6_H-512_A-8':\n",
    "            'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-6_H-512_A-8/1',\n",
    "        'small_bert/bert_en_uncased_L-6_H-768_A-12':\n",
    "            'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-6_H-768_A-12/1',\n",
    "        'small_bert/bert_en_uncased_L-8_H-128_A-2':\n",
    "            'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-8_H-128_A-2/1',\n",
    "        'small_bert/bert_en_uncased_L-8_H-256_A-4':\n",
    "            'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-8_H-256_A-4/1',\n",
    "        'small_bert/bert_en_uncased_L-8_H-512_A-8':\n",
    "            'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-8_H-512_A-8/1',\n",
    "        'small_bert/bert_en_uncased_L-8_H-768_A-12':\n",
    "            'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-8_H-768_A-12/1',\n",
    "        'small_bert/bert_en_uncased_L-10_H-128_A-2':\n",
    "            'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-10_H-128_A-2/1',\n",
    "        'small_bert/bert_en_uncased_L-10_H-256_A-4':\n",
    "            'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-10_H-256_A-4/1',\n",
    "        'small_bert/bert_en_uncased_L-10_H-512_A-8':\n",
    "            'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-10_H-512_A-8/1',\n",
    "        'small_bert/bert_en_uncased_L-10_H-768_A-12':\n",
    "            'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-10_H-768_A-12/1',\n",
    "        'small_bert/bert_en_uncased_L-12_H-128_A-2':\n",
    "            'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-12_H-128_A-2/1',\n",
    "        'small_bert/bert_en_uncased_L-12_H-256_A-4':\n",
    "            'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-12_H-256_A-4/1',\n",
    "        'small_bert/bert_en_uncased_L-12_H-512_A-8':\n",
    "            'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-12_H-512_A-8/1',\n",
    "        'small_bert/bert_en_uncased_L-12_H-768_A-12':\n",
    "            'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-12_H-768_A-12/1',\n",
    "        'albert_en_base':\n",
    "            'https://tfhub.dev/tensorflow/albert_en_base/2',\n",
    "        'electra_small':\n",
    "            'https://tfhub.dev/google/electra_small/2',\n",
    "        'electra_base':\n",
    "            'https://tfhub.dev/google/electra_base/2',\n",
    "        'experts_pubmed':\n",
    "            'https://tfhub.dev/google/experts/bert/pubmed/2',\n",
    "        'experts_wiki_books':\n",
    "            'https://tfhub.dev/google/experts/bert/wiki_books/2',\n",
    "        'talking-heads_base':\n",
    "            'https://tfhub.dev/tensorflow/talkheads_ggelu_bert_en_base/1',\n",
    "    }\n",
    "\n",
    "    map_model_to_preprocess = {\n",
    "        'bert_en_uncased_L-12_H-768_A-12':\n",
    "            'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
    "        'bert_en_cased_L-12_H-768_A-12':\n",
    "            'https://tfhub.dev/tensorflow/bert_en_cased_preprocess/3',\n",
    "        'small_bert/bert_en_uncased_L-2_H-128_A-2':\n",
    "            'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
    "        'small_bert/bert_en_uncased_L-2_H-256_A-4':\n",
    "            'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
    "        'small_bert/bert_en_uncased_L-2_H-512_A-8':\n",
    "            'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
    "        'small_bert/bert_en_uncased_L-2_H-768_A-12':\n",
    "            'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
    "        'small_bert/bert_en_uncased_L-4_H-128_A-2':\n",
    "            'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
    "        'small_bert/bert_en_uncased_L-4_H-256_A-4':\n",
    "            'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
    "        'small_bert/bert_en_uncased_L-4_H-512_A-8':\n",
    "            'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
    "        'small_bert/bert_en_uncased_L-4_H-768_A-12':\n",
    "            'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
    "        'small_bert/bert_en_uncased_L-6_H-128_A-2':\n",
    "            'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
    "        'small_bert/bert_en_uncased_L-6_H-256_A-4':\n",
    "            'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
    "        'small_bert/bert_en_uncased_L-6_H-512_A-8':\n",
    "            'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
    "        'small_bert/bert_en_uncased_L-6_H-768_A-12':\n",
    "            'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
    "        'small_bert/bert_en_uncased_L-8_H-128_A-2':\n",
    "            'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
    "        'small_bert/bert_en_uncased_L-8_H-256_A-4':\n",
    "            'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
    "        'small_bert/bert_en_uncased_L-8_H-512_A-8':\n",
    "            'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
    "        'small_bert/bert_en_uncased_L-8_H-768_A-12':\n",
    "            'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
    "        'small_bert/bert_en_uncased_L-10_H-128_A-2':\n",
    "            'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
    "        'small_bert/bert_en_uncased_L-10_H-256_A-4':\n",
    "            'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
    "        'small_bert/bert_en_uncased_L-10_H-512_A-8':\n",
    "            'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
    "        'small_bert/bert_en_uncased_L-10_H-768_A-12':\n",
    "            'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
    "        'small_bert/bert_en_uncased_L-12_H-128_A-2':\n",
    "            'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
    "        'small_bert/bert_en_uncased_L-12_H-256_A-4':\n",
    "            'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
    "        'small_bert/bert_en_uncased_L-12_H-512_A-8':\n",
    "            'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
    "        'small_bert/bert_en_uncased_L-12_H-768_A-12':\n",
    "            'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
    "        'bert_multi_cased_L-12_H-768_A-12':\n",
    "            'https://tfhub.dev/tensorflow/bert_multi_cased_preprocess/3',\n",
    "        'albert_en_base':\n",
    "            'https://tfhub.dev/tensorflow/albert_en_preprocess/3',\n",
    "        'electra_small':\n",
    "            'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
    "        'electra_base':\n",
    "            'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
    "        'experts_pubmed':\n",
    "            'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
    "        'experts_wiki_books':\n",
    "            'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
    "        'talking-heads_base':\n",
    "            'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
    "    }\n",
    "\n",
    "    tfhub_handle_encoder = map_name_to_handle[bert_model_name]\n",
    "    tfhub_handle_preprocess = map_model_to_preprocess[bert_model_name]\n",
    "\n",
    "    print(f'BERT model selected           : {tfhub_handle_encoder}')\n",
    "    print(f'Preprocess model auto-selected: {tfhub_handle_preprocess}')\n",
    "    return tfhub_handle_preprocess, tfhub_handle_encoder\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "class InquiryAnalyzerBERTModel(keras.Model):\n",
    "\n",
    "    def __init__(self, tfhub_handle_preprocess: str, tfhub_handle_encoder: str, *args, **kwargs):\n",
    "        super().__init__(*args, **kwargs)\n",
    "        self.input_layer = keras.Input(shape=(), dtype=tf.string, name=\"INPUT\")\n",
    "        self.preprocess_layer = hub.KerasLayer(tfhub_handle_preprocess, name=\"PREPROCESS\")\n",
    "        self.encoder_layer = hub.KerasLayer(tfhub_handle_encoder, trainable=True, name=\"BERT_ENCODER\")\n",
    "        self.dropout = keras.layers.Dropout(0.1, name=\"DROPOUT\")\n",
    "        self.dense = keras.layers.Dense(10, activation=\"softmax\", name=\"FINAL_CLASSIFIER\")\n",
    "\n",
    "    def call(self, inputs, training=None, mask=None):\n",
    "        # y = self.input_layer(inputs)\n",
    "        y = self.preprocess_layer(inputs)\n",
    "        y = self.encoder_layer(y)['pooled_output']\n",
    "        y = self.dropout(y)\n",
    "        y = self.dense(y)\n",
    "        return y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "class InquiryAnalyzerBERT:\n",
    "    def __init__(self, model):\n",
    "        self.model = model\n",
    "        pass\n",
    "\n",
    "    def train(self, ds: tf.data.Dataset, epochs: int=100):\n",
    "        optimizer = InquiryAnalyzerBERT.get_optimizer(ds, epochs)\n",
    "        loss = InquiryAnalyzerBERT.get_loss()\n",
    "        metrics = InquiryAnalyzerBERT.get_metrics()\n",
    "        self.model.compile(optimizer=optimizer, loss=loss, metrics=metrics)\n",
    "        print(self.model)\n",
    "        logs = self.model.fit(x=ds, epochs=epochs)\n",
    "        return logs\n",
    "    \n",
    "    @staticmethod\n",
    "    def get_optimizer(ds: tf.data.Dataset, epochs: int):\n",
    "        steps_per_epoch = tf.data.experimental.cardinality(ds).numpy()\n",
    "        num_train_steps = steps_per_epoch * epochs\n",
    "        # used to increase the learning rate of the first 10% of the dataset\n",
    "        num_warmup_steps = int(0.1 * num_train_steps)\n",
    "\n",
    "        init_lr = 3e-5\n",
    "        optimizer = optimization.create_optimizer(init_lr=init_lr, num_train_steps=num_train_steps,\n",
    "                                                  num_warmup_steps=num_warmup_steps, optimizer_type=\"adamw\")\n",
    "        return optimizer\n",
    "    @staticmethod\n",
    "    def get_loss():\n",
    "        loss = tf.keras.losses.BinaryCrossentropy()\n",
    "        return loss\n",
    "    @staticmethod\n",
    "    def get_metrics():\n",
    "        metrics = tf.metrics.BinaryAccuracy()\n",
    "        return metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "def classifierstring(a: np.ndarray):\n",
    "    result = [\"\" for i in a]\n",
    "    for i, el in enumerate(a):\n",
    "        if a[i, 4] == 1:\n",
    "            result[i] += \"ORDER \"\n",
    "        if a[i, 2] == 1:\n",
    "            result[i] += \"SEARCH \"\n",
    "        if a[i, 3] == 1:\n",
    "            result[i] += \"DELIVERY \"\n",
    "        if a[i, 7] == 1:\n",
    "            result[i] += \"CHECKOUT \"\n",
    "        if a[i, 0] == 1:\n",
    "            result[i] += \"USER INTERACTION NEEDED\"\n",
    "        if a[i, 1] == 1:\n",
    "            result[i] += \"CONTACT\"\n",
    "        if a[i, 8] == 1:\n",
    "            result[i] += \"REQUEST \"\n",
    "        if a[i, 6] == 1:\n",
    "            result[i] += \"FEEDBACK \"\n",
    "        if a[i, 5] == 1:\n",
    "            result[i] += \"WELCOME \"\n",
    "        if a[i, 9] == 1:\n",
    "            result[i] += \"RECOMMENDATION \"\n",
    "    return result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "def get_ds(BATCH_SIZE: int, dataset_path: str):\n",
    "    npdataset = InquiryDataset.get_training_dataset(dataset_path)\n",
    "    train_examples = tf.convert_to_tensor(npdataset[:, 0], dtype=tf.string)\n",
    "    train_labels = np.stack(npdataset[:, 1])\n",
    "    assert train_labels.shape[2] == 10\n",
    "    train_labels = train_labels.reshape((npdataset[:, 1].shape[0], 10))  # tensorflow can't convert labels easily\n",
    "    train_labels = tf.convert_to_tensor(train_labels, dtype=tf.int32)\n",
    "    dataset = tf.data.Dataset.from_tensor_slices((train_examples, train_labels))\n",
    "    train_ds = dataset.batch(BATCH_SIZE, drop_remainder=False).cache().prefetch(buffer_size=tf.data.AUTOTUNE)\n",
    "    return train_ds\n",
    "\n",
    "\n",
    "def train(savepath, epochs=1000, model: keras.Model=None):\n",
    "    # assert(type(savepath) == str and callback == None or type(callback) == keras.callbacks.ModelCheckpoint)\n",
    "    BATCH_SIZE = 32\n",
    "    # lets get the dataset first\n",
    "    train_ds = get_ds(BATCH_SIZE, \"D:\\\\Documents\\\\Code\\\\Stock\\\\NNS\\\\inquiryProcessor\\\\inquiries_dataset.csv\", ) # TODO: TYPE IN YOUR GIT PATH\n",
    "    print(train_ds)\n",
    "    # TODO: SOLVE THIS LOCAL PATH PROBLEM\n",
    "    if model == None:\n",
    "        tfhub_handle_preprocess, tfhub_handle_encoder = get_bert_details()\n",
    "        model = InquiryAnalyzerBERTModel(tfhub_handle_preprocess, tfhub_handle_encoder)\n",
    "    analyzer = InquiryAnalyzerBERT(model)\n",
    "    logs = analyzer.train(ds=train_ds, epochs=epochs)\n",
    "    model.save(savepath, save_format=\"tf\")  # creates a folder inside NNS/InquiryProcessor\\\n",
    "    return logs\n",
    "\n",
    "\n",
    "def get_model_from_file(filepath, ds: tf.data.Dataset, epochs: int):\n",
    "    model = keras.models.load_model(filepath, custom_objects={\"AdamWeightDecay\": InquiryAnalyzerBERT.get_optimizer(ds, epochs)})\n",
    "    return model\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BERT model selected           : https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-4_H-512_A-8/1\n",
      "Preprocess model auto-selected: https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3\n",
      "D:\\Documents\\Code\\Stock\\NNS\\inquiryProcessor\\inquiries_dataset.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\senya\\AppData\\Local\\Temp/ipykernel_12488/3110488194.py:2: FutureWarning: The error_bad_lines argument has been deprecated and will be removed in a future version.\n",
      "\n",
      "\n",
      "  npdataset = InquiryDataset.get_training_dataset(dataset_path)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<PrefetchDataset shapes: ((None,), (None, 10)), types: (tf.string, tf.int32)>\n",
      "<__main__.InquiryAnalyzerBERTModel object at 0x0000026F22150B20>\n",
      "Epoch 1/100\n",
      "8/8 [==============================] - 119s 14s/step - loss: 0.9171 - binary_accuracy: 0.8922\n",
      "Epoch 2/100\n",
      "8/8 [==============================] - 112s 14s/step - loss: 0.8173 - binary_accuracy: 0.8918\n",
      "Epoch 3/100\n",
      "8/8 [==============================] - 109s 14s/step - loss: 0.6608 - binary_accuracy: 0.8922\n",
      "Epoch 4/100\n",
      "8/8 [==============================] - 113s 14s/step - loss: 0.5103 - binary_accuracy: 0.8922\n",
      "Epoch 5/100\n",
      "8/8 [==============================] - 111s 14s/step - loss: 0.3931 - binary_accuracy: 0.8918\n",
      "Epoch 6/100\n",
      "8/8 [==============================] - 104s 13s/step - loss: 0.3354 - binary_accuracy: 0.8926\n",
      "Epoch 7/100\n",
      "8/8 [==============================] - 106s 13s/step - loss: 0.2985 - binary_accuracy: 0.8930\n",
      "Epoch 8/100\n",
      "8/8 [==============================] - 104s 13s/step - loss: 0.2760 - binary_accuracy: 0.8977\n",
      "Epoch 9/100\n",
      "8/8 [==============================] - 104s 13s/step - loss: 0.2545 - binary_accuracy: 0.9035\n",
      "Epoch 10/100\n",
      "8/8 [==============================] - 104s 13s/step - loss: 0.2287 - binary_accuracy: 0.9191\n",
      "Epoch 11/100\n",
      "8/8 [==============================] - 104s 13s/step - loss: 0.2037 - binary_accuracy: 0.9313\n",
      "Epoch 12/100\n",
      "8/8 [==============================] - 104s 13s/step - loss: 0.1792 - binary_accuracy: 0.9453\n",
      "Epoch 13/100\n",
      "8/8 [==============================] - 104s 13s/step - loss: 0.1633 - binary_accuracy: 0.9480\n",
      "Epoch 14/100\n",
      "8/8 [==============================] - 104s 13s/step - loss: 0.1444 - binary_accuracy: 0.9559\n",
      "Epoch 15/100\n",
      "8/8 [==============================] - 104s 13s/step - loss: 0.1316 - binary_accuracy: 0.9613\n",
      "Epoch 16/100\n",
      "8/8 [==============================] - 103s 13s/step - loss: 0.1205 - binary_accuracy: 0.9691\n",
      "Epoch 17/100\n",
      "8/8 [==============================] - 92s 12s/step - loss: 0.1070 - binary_accuracy: 0.9730\n",
      "Epoch 18/100\n",
      "8/8 [==============================] - 92s 12s/step - loss: 0.0971 - binary_accuracy: 0.9762\n",
      "Epoch 19/100\n",
      "8/8 [==============================] - 92s 11s/step - loss: 0.0865 - binary_accuracy: 0.9832\n",
      "Epoch 20/100\n",
      "8/8 [==============================] - 92s 11s/step - loss: 0.0787 - binary_accuracy: 0.9859\n",
      "Epoch 21/100\n",
      "8/8 [==============================] - 97s 12s/step - loss: 0.0750 - binary_accuracy: 0.9832\n",
      "Epoch 22/100\n",
      "8/8 [==============================] - 106s 13s/step - loss: 0.0654 - binary_accuracy: 0.9883\n",
      "Epoch 23/100\n",
      "8/8 [==============================] - 103s 13s/step - loss: 0.0635 - binary_accuracy: 0.9875\n",
      "Epoch 24/100\n",
      "8/8 [==============================] - 105s 13s/step - loss: 0.0576 - binary_accuracy: 0.9887\n",
      "Epoch 25/100\n",
      "8/8 [==============================] - 104s 13s/step - loss: 0.0521 - binary_accuracy: 0.9895\n",
      "Epoch 26/100\n",
      "8/8 [==============================] - 105s 13s/step - loss: 0.0486 - binary_accuracy: 0.9910\n",
      "Epoch 27/100\n",
      "8/8 [==============================] - 107s 13s/step - loss: 0.0468 - binary_accuracy: 0.9902\n",
      "Epoch 28/100\n",
      "8/8 [==============================] - 105s 13s/step - loss: 0.0434 - binary_accuracy: 0.9910\n",
      "Epoch 29/100\n",
      "8/8 [==============================] - 105s 13s/step - loss: 0.0411 - binary_accuracy: 0.9910\n",
      "Epoch 30/100\n",
      "8/8 [==============================] - 103s 13s/step - loss: 0.0395 - binary_accuracy: 0.9914\n",
      "Epoch 31/100\n",
      "8/8 [==============================] - 105s 13s/step - loss: 0.0356 - binary_accuracy: 0.9914\n",
      "Epoch 32/100\n",
      "8/8 [==============================] - 104s 13s/step - loss: 0.0341 - binary_accuracy: 0.9918\n",
      "Epoch 33/100\n",
      "8/8 [==============================] - 103s 13s/step - loss: 0.0321 - binary_accuracy: 0.9918\n",
      "Epoch 34/100\n",
      "8/8 [==============================] - 93s 12s/step - loss: 0.0304 - binary_accuracy: 0.9914\n",
      "Epoch 35/100\n",
      "8/8 [==============================] - 92s 12s/step - loss: 0.0288 - binary_accuracy: 0.9898\n",
      "Epoch 36/100\n",
      "8/8 [==============================] - 93s 12s/step - loss: 0.0280 - binary_accuracy: 0.9918\n",
      "Epoch 37/100\n",
      "8/8 [==============================] - 93s 12s/step - loss: 0.0260 - binary_accuracy: 0.9918\n",
      "Epoch 38/100\n",
      "8/8 [==============================] - 92s 12s/step - loss: 0.0247 - binary_accuracy: 0.9922\n",
      "Epoch 39/100\n",
      "8/8 [==============================] - 93s 12s/step - loss: 0.0244 - binary_accuracy: 0.9918\n",
      "Epoch 40/100\n",
      "8/8 [==============================] - 93s 12s/step - loss: 0.0234 - binary_accuracy: 0.9918\n",
      "Epoch 41/100\n",
      "8/8 [==============================] - 135s 18s/step - loss: 0.0235 - binary_accuracy: 0.9922\n",
      "Epoch 42/100\n",
      "8/8 [==============================] - 113s 14s/step - loss: 0.0224 - binary_accuracy: 0.9922\n",
      "Epoch 43/100\n",
      "8/8 [==============================] - 102s 13s/step - loss: 0.0219 - binary_accuracy: 0.9914\n",
      "Epoch 44/100\n",
      "8/8 [==============================] - 102s 13s/step - loss: 0.0208 - binary_accuracy: 0.9918\n",
      "Epoch 45/100\n",
      "8/8 [==============================] - 103s 13s/step - loss: 0.0202 - binary_accuracy: 0.9918\n",
      "Epoch 46/100\n",
      "8/8 [==============================] - 103s 13s/step - loss: 0.0194 - binary_accuracy: 0.9918\n",
      "Epoch 47/100\n",
      "8/8 [==============================] - 102s 13s/step - loss: 0.0190 - binary_accuracy: 0.9918\n",
      "Epoch 48/100\n",
      "8/8 [==============================] - 102s 13s/step - loss: 0.0184 - binary_accuracy: 0.9922\n",
      "Epoch 49/100\n",
      "8/8 [==============================] - 102s 13s/step - loss: 0.0177 - binary_accuracy: 0.9922\n",
      "Epoch 50/100\n",
      "8/8 [==============================] - 102s 13s/step - loss: 0.0178 - binary_accuracy: 0.9922\n",
      "Epoch 51/100\n",
      "8/8 [==============================] - 103s 13s/step - loss: 0.0169 - binary_accuracy: 0.9918\n",
      "Epoch 52/100\n",
      "8/8 [==============================] - 101s 13s/step - loss: 0.0171 - binary_accuracy: 0.9918\n",
      "Epoch 53/100\n",
      "8/8 [==============================] - 101s 13s/step - loss: 0.0171 - binary_accuracy: 0.9922\n",
      "Epoch 54/100\n",
      "8/8 [==============================] - 99s 12s/step - loss: 0.0165 - binary_accuracy: 0.9922\n",
      "Epoch 55/100\n",
      "8/8 [==============================] - 91s 11s/step - loss: 0.0162 - binary_accuracy: 0.9922\n",
      "Epoch 56/100\n",
      "8/8 [==============================] - 91s 11s/step - loss: 0.0155 - binary_accuracy: 0.9922\n",
      "Epoch 57/100\n",
      "8/8 [==============================] - 100s 13s/step - loss: 0.0153 - binary_accuracy: 0.9918\n",
      "Epoch 58/100\n",
      "8/8 [==============================] - 102s 13s/step - loss: 0.0146 - binary_accuracy: 0.9918\n",
      "Epoch 59/100\n",
      "8/8 [==============================] - 103s 13s/step - loss: 0.0149 - binary_accuracy: 0.9918\n",
      "Epoch 60/100\n",
      "8/8 [==============================] - 102s 13s/step - loss: 0.0143 - binary_accuracy: 0.9922\n",
      "Epoch 61/100\n",
      "8/8 [==============================] - 101s 13s/step - loss: 0.0145 - binary_accuracy: 0.9918\n",
      "Epoch 62/100\n",
      "8/8 [==============================] - 100s 12s/step - loss: 0.0139 - binary_accuracy: 0.9918\n",
      "Epoch 63/100\n",
      "8/8 [==============================] - 102s 13s/step - loss: 0.0137 - binary_accuracy: 0.9914\n",
      "Epoch 64/100\n",
      "8/8 [==============================] - 102s 13s/step - loss: 0.0132 - binary_accuracy: 0.9922\n",
      "Epoch 65/100\n",
      "8/8 [==============================] - 102s 13s/step - loss: 0.0137 - binary_accuracy: 0.9922\n",
      "Epoch 66/100\n",
      "8/8 [==============================] - 102s 13s/step - loss: 0.0127 - binary_accuracy: 0.9922\n",
      "Epoch 67/100\n",
      "8/8 [==============================] - 101s 13s/step - loss: 0.0129 - binary_accuracy: 0.9918\n",
      "Epoch 68/100\n",
      "8/8 [==============================] - 101s 13s/step - loss: 0.0125 - binary_accuracy: 0.9918\n",
      "Epoch 69/100\n",
      "8/8 [==============================] - 92s 11s/step - loss: 0.0132 - binary_accuracy: 0.9918\n",
      "Epoch 70/100\n",
      "8/8 [==============================] - 92s 11s/step - loss: 0.0126 - binary_accuracy: 0.9914\n",
      "Epoch 71/100\n",
      "8/8 [==============================] - 104s 13s/step - loss: 0.0127 - binary_accuracy: 0.9918\n",
      "Epoch 72/100\n",
      "8/8 [==============================] - 102s 13s/step - loss: 0.0125 - binary_accuracy: 0.9922\n",
      "Epoch 73/100\n",
      "8/8 [==============================] - 100s 13s/step - loss: 0.0122 - binary_accuracy: 0.9922\n",
      "Epoch 74/100\n",
      "8/8 [==============================] - 104s 13s/step - loss: 0.0119 - binary_accuracy: 0.9922\n",
      "Epoch 75/100\n",
      "8/8 [==============================] - 102s 13s/step - loss: 0.0120 - binary_accuracy: 0.9918\n",
      "Epoch 76/100\n",
      "8/8 [==============================] - 101s 13s/step - loss: 0.0117 - binary_accuracy: 0.9914\n",
      "Epoch 77/100\n",
      "8/8 [==============================] - 100s 13s/step - loss: 0.0117 - binary_accuracy: 0.9922\n",
      "Epoch 78/100\n",
      "8/8 [==============================] - 102s 13s/step - loss: 0.0117 - binary_accuracy: 0.9910\n",
      "Epoch 79/100\n",
      "8/8 [==============================] - 101s 13s/step - loss: 0.0120 - binary_accuracy: 0.9922\n",
      "Epoch 80/100\n",
      "8/8 [==============================] - 100s 12s/step - loss: 0.0113 - binary_accuracy: 0.9914\n",
      "Epoch 81/100\n",
      "8/8 [==============================] - 102s 13s/step - loss: 0.0113 - binary_accuracy: 0.9918\n",
      "Epoch 82/100\n",
      "8/8 [==============================] - 100s 12s/step - loss: 0.0112 - binary_accuracy: 0.9918\n",
      "Epoch 83/100\n",
      "8/8 [==============================] - 100s 13s/step - loss: 0.0117 - binary_accuracy: 0.9918\n",
      "Epoch 84/100\n",
      "8/8 [==============================] - 90s 11s/step - loss: 0.0112 - binary_accuracy: 0.9918\n",
      "Epoch 85/100\n",
      "8/8 [==============================] - 91s 11s/step - loss: 0.0113 - binary_accuracy: 0.9922\n",
      "Epoch 86/100\n",
      "8/8 [==============================] - 89s 11s/step - loss: 0.0111 - binary_accuracy: 0.9918\n",
      "Epoch 87/100\n",
      "8/8 [==============================] - 90s 11s/step - loss: 0.0110 - binary_accuracy: 0.9922\n",
      "Epoch 88/100\n",
      "8/8 [==============================] - 91s 11s/step - loss: 0.0109 - binary_accuracy: 0.9918\n",
      "Epoch 89/100\n",
      "8/8 [==============================] - 91s 11s/step - loss: 0.0109 - binary_accuracy: 0.9914\n",
      "Epoch 90/100\n",
      "8/8 [==============================] - 91s 11s/step - loss: 0.0108 - binary_accuracy: 0.9914\n",
      "Epoch 91/100\n",
      "8/8 [==============================] - 91s 11s/step - loss: 0.0107 - binary_accuracy: 0.9918\n",
      "Epoch 92/100\n",
      "8/8 [==============================] - 90s 11s/step - loss: 0.0106 - binary_accuracy: 0.9918\n",
      "Epoch 93/100\n",
      "8/8 [==============================] - 91s 11s/step - loss: 0.0108 - binary_accuracy: 0.9922\n",
      "Epoch 94/100\n",
      "8/8 [==============================] - 91s 11s/step - loss: 0.0106 - binary_accuracy: 0.9918\n",
      "Epoch 95/100\n",
      "8/8 [==============================] - 91s 11s/step - loss: 0.0105 - binary_accuracy: 0.9922\n",
      "Epoch 96/100\n",
      "8/8 [==============================] - 90s 11s/step - loss: 0.0106 - binary_accuracy: 0.9922\n",
      "Epoch 97/100\n",
      "8/8 [==============================] - 90s 11s/step - loss: 0.0103 - binary_accuracy: 0.9918\n",
      "Epoch 98/100\n",
      "8/8 [==============================] - 91s 11s/step - loss: 0.0105 - binary_accuracy: 0.9918\n",
      "Epoch 99/100\n",
      "8/8 [==============================] - 90s 11s/step - loss: 0.0103 - binary_accuracy: 0.9922\n",
      "Epoch 100/100\n",
      "8/8 [==============================] - 91s 11s/step - loss: 0.0102 - binary_accuracy: 0.9922\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as restored_function_body, restored_function_body, restored_function_body, restored_function_body, restored_function_body while saving (showing 5 of 310). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: InquiryEstimatorBERT_Model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: InquiryEstimatorBERT_Model\\assets\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x26f143481c0>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "savepath = \"InquiryEstimatorBERT_Model\"\n",
    "a,b = get_bert_details()\n",
    "model = InquiryAnalyzerBERTModel(a,b)\n",
    "train(savepath=savepath, model=model, epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"inquiry_analyzer_bert_model_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "PREPROCESS (KerasLayer)      multiple                  0         \n",
      "_________________________________________________________________\n",
      "BERT_ENCODER (KerasLayer)    multiple                  28763649  \n",
      "_________________________________________________________________\n",
      "DROPOUT (Dropout)            multiple                  0         \n",
      "_________________________________________________________________\n",
      "FINAL_CLASSIFIER (Dense)     multiple                  5130      \n",
      "=================================================================\n",
      "Total params: 28,768,779\n",
      "Trainable params: 28,768,778\n",
      "Non-trainable params: 1\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "def classify(a: list) -> Tuple[str, np.ndarray]:\n",
    "    for i in a:\n",
    "        assert type(i) == str\n",
    "    result_tensor = model.call(tf.convert_to_tensor(tf.convert_to_tensor(a)))\n",
    "    result_np = result_tensor.numpy()\n",
    "    return classifierstring(result_np.round()), result_np.round()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['FEEDBACK '],\n",
       " array([[0., 0., 0., 0., 0., 0., 1., 0., 0., 0.]], dtype=float32))"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classify([\"Hi, I've ordered pizza Chicago a week ago and I would like to say that it was the best pizza I've ever tried in my life! It's gorgeous and delicious as hell. I have no idea how these guys are doing it!\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.7.1'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.__version__"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "7b4b4feff2f24a0f0a34464dbe537a36fda679851528fb8735cb41fa49dffb2d"
  },
  "kernelspec": {
   "display_name": "Python 3.8.8 64-bit ('base': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
