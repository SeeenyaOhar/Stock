{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "import os\n",
    "\n",
    "sys.path.append(\"D:\\\\documents\\\\code\\\\Stock\\\\NNS\\\\inquiryProcessor\")\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"-1\"\n",
    "import shutil\n",
    "from typing import Tuple\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub\n",
    "import tensorflow.keras as keras\n",
    "import tensorflow_text as text\n",
    "from official.nlp import optimization  # to create AdamW optimizer\n",
    "from dataset import InquiryDataset\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "def get_bert_details():\n",
    "    \"\"\"\n",
    "    Returns handle encoder and bert model links.\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    bert_model_name = 'small_bert/bert_en_uncased_L-4_H-512_A-8'\n",
    "\n",
    "    map_name_to_handle = {\n",
    "        'bert_en_uncased_L-12_H-768_A-12':\n",
    "            'https://tfhub.dev/tensorflow/bert_en_uncased_L-12_H-768_A-12/3',\n",
    "        'bert_en_cased_L-12_H-768_A-12':\n",
    "            'https://tfhub.dev/tensorflow/bert_en_cased_L-12_H-768_A-12/3',\n",
    "        'bert_multi_cased_L-12_H-768_A-12':\n",
    "            'https://tfhub.dev/tensorflow/bert_multi_cased_L-12_H-768_A-12/3',\n",
    "        'small_bert/bert_en_uncased_L-2_H-128_A-2':\n",
    "            'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-2_H-128_A-2/1',\n",
    "        'small_bert/bert_en_uncased_L-2_H-256_A-4':\n",
    "            'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-2_H-256_A-4/1',\n",
    "        'small_bert/bert_en_uncased_L-2_H-512_A-8':\n",
    "            'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-2_H-512_A-8/1',\n",
    "        'small_bert/bert_en_uncased_L-2_H-768_A-12':\n",
    "            'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-2_H-768_A-12/1',\n",
    "        'small_bert/bert_en_uncased_L-4_H-128_A-2':\n",
    "            'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-4_H-128_A-2/1',\n",
    "        'small_bert/bert_en_uncased_L-4_H-256_A-4':\n",
    "            'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-4_H-256_A-4/1',\n",
    "        'small_bert/bert_en_uncased_L-4_H-512_A-8':\n",
    "            'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-4_H-512_A-8/1',\n",
    "        'small_bert/bert_en_uncased_L-4_H-768_A-12':\n",
    "            'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-4_H-768_A-12/1',\n",
    "        'small_bert/bert_en_uncased_L-6_H-128_A-2':\n",
    "            'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-6_H-128_A-2/1',\n",
    "        'small_bert/bert_en_uncased_L-6_H-256_A-4':\n",
    "            'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-6_H-256_A-4/1',\n",
    "        'small_bert/bert_en_uncased_L-6_H-512_A-8':\n",
    "            'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-6_H-512_A-8/1',\n",
    "        'small_bert/bert_en_uncased_L-6_H-768_A-12':\n",
    "            'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-6_H-768_A-12/1',\n",
    "        'small_bert/bert_en_uncased_L-8_H-128_A-2':\n",
    "            'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-8_H-128_A-2/1',\n",
    "        'small_bert/bert_en_uncased_L-8_H-256_A-4':\n",
    "            'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-8_H-256_A-4/1',\n",
    "        'small_bert/bert_en_uncased_L-8_H-512_A-8':\n",
    "            'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-8_H-512_A-8/1',\n",
    "        'small_bert/bert_en_uncased_L-8_H-768_A-12':\n",
    "            'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-8_H-768_A-12/1',\n",
    "        'small_bert/bert_en_uncased_L-10_H-128_A-2':\n",
    "            'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-10_H-128_A-2/1',\n",
    "        'small_bert/bert_en_uncased_L-10_H-256_A-4':\n",
    "            'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-10_H-256_A-4/1',\n",
    "        'small_bert/bert_en_uncased_L-10_H-512_A-8':\n",
    "            'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-10_H-512_A-8/1',\n",
    "        'small_bert/bert_en_uncased_L-10_H-768_A-12':\n",
    "            'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-10_H-768_A-12/1',\n",
    "        'small_bert/bert_en_uncased_L-12_H-128_A-2':\n",
    "            'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-12_H-128_A-2/1',\n",
    "        'small_bert/bert_en_uncased_L-12_H-256_A-4':\n",
    "            'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-12_H-256_A-4/1',\n",
    "        'small_bert/bert_en_uncased_L-12_H-512_A-8':\n",
    "            'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-12_H-512_A-8/1',\n",
    "        'small_bert/bert_en_uncased_L-12_H-768_A-12':\n",
    "            'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-12_H-768_A-12/1',\n",
    "        'albert_en_base':\n",
    "            'https://tfhub.dev/tensorflow/albert_en_base/2',\n",
    "        'electra_small':\n",
    "            'https://tfhub.dev/google/electra_small/2',\n",
    "        'electra_base':\n",
    "            'https://tfhub.dev/google/electra_base/2',\n",
    "        'experts_pubmed':\n",
    "            'https://tfhub.dev/google/experts/bert/pubmed/2',\n",
    "        'experts_wiki_books':\n",
    "            'https://tfhub.dev/google/experts/bert/wiki_books/2',\n",
    "        'talking-heads_base':\n",
    "            'https://tfhub.dev/tensorflow/talkheads_ggelu_bert_en_base/1',\n",
    "    }\n",
    "\n",
    "    map_model_to_preprocess = {\n",
    "        'bert_en_uncased_L-12_H-768_A-12':\n",
    "            'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
    "        'bert_en_cased_L-12_H-768_A-12':\n",
    "            'https://tfhub.dev/tensorflow/bert_en_cased_preprocess/3',\n",
    "        'small_bert/bert_en_uncased_L-2_H-128_A-2':\n",
    "            'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
    "        'small_bert/bert_en_uncased_L-2_H-256_A-4':\n",
    "            'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
    "        'small_bert/bert_en_uncased_L-2_H-512_A-8':\n",
    "            'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
    "        'small_bert/bert_en_uncased_L-2_H-768_A-12':\n",
    "            'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
    "        'small_bert/bert_en_uncased_L-4_H-128_A-2':\n",
    "            'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
    "        'small_bert/bert_en_uncased_L-4_H-256_A-4':\n",
    "            'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
    "        'small_bert/bert_en_uncased_L-4_H-512_A-8':\n",
    "            'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
    "        'small_bert/bert_en_uncased_L-4_H-768_A-12':\n",
    "            'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
    "        'small_bert/bert_en_uncased_L-6_H-128_A-2':\n",
    "            'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
    "        'small_bert/bert_en_uncased_L-6_H-256_A-4':\n",
    "            'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
    "        'small_bert/bert_en_uncased_L-6_H-512_A-8':\n",
    "            'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
    "        'small_bert/bert_en_uncased_L-6_H-768_A-12':\n",
    "            'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
    "        'small_bert/bert_en_uncased_L-8_H-128_A-2':\n",
    "            'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
    "        'small_bert/bert_en_uncased_L-8_H-256_A-4':\n",
    "            'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
    "        'small_bert/bert_en_uncased_L-8_H-512_A-8':\n",
    "            'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
    "        'small_bert/bert_en_uncased_L-8_H-768_A-12':\n",
    "            'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
    "        'small_bert/bert_en_uncased_L-10_H-128_A-2':\n",
    "            'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
    "        'small_bert/bert_en_uncased_L-10_H-256_A-4':\n",
    "            'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
    "        'small_bert/bert_en_uncased_L-10_H-512_A-8':\n",
    "            'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
    "        'small_bert/bert_en_uncased_L-10_H-768_A-12':\n",
    "            'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
    "        'small_bert/bert_en_uncased_L-12_H-128_A-2':\n",
    "            'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
    "        'small_bert/bert_en_uncased_L-12_H-256_A-4':\n",
    "            'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
    "        'small_bert/bert_en_uncased_L-12_H-512_A-8':\n",
    "            'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
    "        'small_bert/bert_en_uncased_L-12_H-768_A-12':\n",
    "            'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
    "        'bert_multi_cased_L-12_H-768_A-12':\n",
    "            'https://tfhub.dev/tensorflow/bert_multi_cased_preprocess/3',\n",
    "        'albert_en_base':\n",
    "            'https://tfhub.dev/tensorflow/albert_en_preprocess/3',\n",
    "        'electra_small':\n",
    "            'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
    "        'electra_base':\n",
    "            'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
    "        'experts_pubmed':\n",
    "            'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
    "        'experts_wiki_books':\n",
    "            'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
    "        'talking-heads_base':\n",
    "            'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
    "    }\n",
    "\n",
    "    tfhub_handle_encoder = map_name_to_handle[bert_model_name]\n",
    "    tfhub_handle_preprocess = map_model_to_preprocess[bert_model_name]\n",
    "\n",
    "    print(f'BERT model selected           : {tfhub_handle_encoder}')\n",
    "    print(f'Preprocess model auto-selected: {tfhub_handle_preprocess}')\n",
    "    return tfhub_handle_preprocess, tfhub_handle_encoder\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "class InquiryAnalyzerBERTModel(keras.Model):\n",
    "\n",
    "    def __init__(self, tfhub_handle_preprocess: str, tfhub_handle_encoder: str, *args, **kwargs):\n",
    "        super().__init__(*args, **kwargs)\n",
    "        self.input_layer = keras.Input(shape=(), dtype=tf.string, name=\"INPUT\")\n",
    "        self.preprocess_layer = hub.KerasLayer(tfhub_handle_preprocess, name=\"PREPROCESS\")\n",
    "        self.encoder_layer = hub.KerasLayer(tfhub_handle_encoder, trainable=True, name=\"BERT_ENCODER\")\n",
    "        self.dropout = keras.layers.Dropout(0.1, name=\"DROPOUT\")\n",
    "        self.dense = keras.layers.Dense(10, activation=\"softmax\", name=\"FINAL_CLASSIFIER\")\n",
    "\n",
    "    def call(self, inputs, training=None, mask=None):\n",
    "        # y = self.input_layer(inputs)\n",
    "        y = self.preprocess_layer(inputs)\n",
    "        y = self.encoder_layer(y)['pooled_output']\n",
    "        y = self.dropout(y)\n",
    "        y = self.dense(y)\n",
    "        return y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "class InquiryAnalyzerBERT:\n",
    "    def __init__(self, model):\n",
    "        self.model = model\n",
    "        pass\n",
    "\n",
    "    def train(self, ds: tf.data.Dataset, epochs: int=100):\n",
    "        optimizer = InquiryAnalyzerBERT.get_optimizer(ds, epochs)\n",
    "        loss = InquiryAnalyzerBERT.get_loss()\n",
    "        metrics = InquiryAnalyzerBERT.get_metrics()\n",
    "        self.model.compile(optimizer=optimizer, loss=loss, metrics=metrics)\n",
    "        print(self.model)\n",
    "        logs = self.model.fit(x=ds, epochs=epochs)\n",
    "        return logs\n",
    "    \n",
    "    @staticmethod\n",
    "    def get_optimizer(ds: tf.data.Dataset, epochs: int):\n",
    "        steps_per_epoch = tf.data.experimental.cardinality(ds).numpy()\n",
    "        num_train_steps = steps_per_epoch * epochs\n",
    "        # used to increase the learning rate of the first 10% of the dataset\n",
    "        num_warmup_steps = int(0.1 * num_train_steps)\n",
    "\n",
    "        init_lr = 3e-5\n",
    "        optimizer = optimization.create_optimizer(init_lr=init_lr, num_train_steps=num_train_steps,\n",
    "                                                  num_warmup_steps=num_warmup_steps, optimizer_type=\"adamw\")\n",
    "        return optimizer\n",
    "    @staticmethod\n",
    "    def get_loss():\n",
    "        loss = tf.keras.losses.BinaryCrossentropy()\n",
    "        return loss\n",
    "    @staticmethod\n",
    "    def get_metrics():\n",
    "        metrics = tf.metrics.BinaryAccuracy()\n",
    "        return metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "def classifierstring(a: np.ndarray):\n",
    "    result = [\"\" for i in a]\n",
    "    for i, el in enumerate(a):\n",
    "        if a[i, 4] == 1:\n",
    "            result[i] += \"ORDER \"\n",
    "        if a[i, 2] == 1:\n",
    "            result[i] += \"SEARCH \"\n",
    "        if a[i, 3] == 1:\n",
    "            result[i] += \"DELIVERY \"\n",
    "        if a[i, 7] == 1:\n",
    "            result[i] += \"CHECKOUT \"\n",
    "        if a[i, 0] == 1:\n",
    "            result[i] += \"USER INTERACTION NEEDED\"\n",
    "        if a[i, 1] == 1:\n",
    "            result[i] += \"CONTACT\"\n",
    "        if a[i, 8] == 1:\n",
    "            result[i] += \"REQUEST \"\n",
    "        if a[i, 6] == 1:\n",
    "            result[i] += \"FEEDBACK \"\n",
    "        if a[i, 5] == 1:\n",
    "            result[i] += \"WELCOME \"\n",
    "        if a[i, 9] == 1:\n",
    "            result[i] += \"RECOMMENDATION \"\n",
    "    return result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "def get_ds(BATCH_SIZE: int, dataset_path: str):\n",
    "    npdataset = InquiryDataset.get_training_dataset(dataset_path)\n",
    "    train_examples = tf.convert_to_tensor(npdataset[:, 0], dtype=tf.string)\n",
    "    train_labels = np.stack(npdataset[:, 1])\n",
    "    assert train_labels.shape[1] == 10\n",
    "    train_labels = train_labels.reshape((npdataset[:, 1].shape[0], 10))  # tensorflow can't convert labels easily\n",
    "    train_labels = tf.convert_to_tensor(train_labels, dtype=tf.int32)\n",
    "    dataset = tf.data.Dataset.from_tensor_slices((train_examples, train_labels))\n",
    "    train_ds = dataset.batch(BATCH_SIZE, drop_remainder=False).cache().prefetch(buffer_size=tf.data.AUTOTUNE)\n",
    "    return train_ds\n",
    "\n",
    "\n",
    "def train(savepath, epochs=1000, model: keras.Model=None):\n",
    "    # assert(type(savepath) == str and callback == None or type(callback) == keras.callbacks.ModelCheckpoint)\n",
    "    BATCH_SIZE = 32\n",
    "    # lets get the dataset first\n",
    "    train_ds = get_ds(BATCH_SIZE, \"D:\\\\Documents\\\\Code\\\\Stock\\\\NNS\\\\inquiryProcessor\\\\inquiries_dataset.csv\", ) # TODO: TYPE IN YOUR GIT PATH\n",
    "    print(train_ds)\n",
    "    # TODO: SOLVE THIS LOCAL PATH PROBLEM\n",
    "    if model == None:\n",
    "        tfhub_handle_preprocess, tfhub_handle_encoder = get_bert_details()\n",
    "        model = InquiryAnalyzerBERTModel(tfhub_handle_preprocess, tfhub_handle_encoder)\n",
    "    analyzer = InquiryAnalyzerBERT(model)\n",
    "    logs = analyzer.train(ds=train_ds, epochs=epochs)\n",
    "    model.save(savepath, save_format=\"tf\")  # creates a folder inside NNS/InquiryProcessor\\\n",
    "    return logs\n",
    "\n",
    "\n",
    "def get_model_from_file(filepath, ds: tf.data.Dataset, epochs: int):\n",
    "    model = keras.models.load_model(filepath, custom_objects={\"AdamWeightDecay\": InquiryAnalyzerBERT.get_optimizer(ds, epochs)})\n",
    "    return model\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"D:\\\\Documents\\\\Code\\\\Stock\\\\NNS\\\\inquiryProcessor\\\\inquiries_dataset.csv\"\n",
    "ds = get_ds(32, path)\n",
    "for i in ds.enumerate():\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BERT model selected           : https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-4_H-512_A-8/1\n",
      "Preprocess model auto-selected: https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3\n",
      "D:\\documents\\code\\Stock\\NNS\\inquiryProcessor\\inquiries_dataset.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\documents\\code\\Stock\\NNS\\inquiryProcessor\\dataset.py:36: FutureWarning: The error_bad_lines argument has been deprecated and will be removed in a future version. Use on_bad_lines in the future.\n",
      "\n",
      "\n",
      "  df = pd.read_csv(dataset_path, error_bad_lines=False)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "D:\\Documents\\Code\\Stock\\NNS\\inquiryProcessor\\inquiries_dataset.csv\n",
      "<PrefetchDataset shapes: ((None,), (None, 10)), types: (tf.string, tf.int32)>\n",
      "<keras.saving.saved_model.load.InquiryAnalyzerBERTModel object at 0x000002B81421A400>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\documents\\code\\Stock\\NNS\\inquiryProcessor\\dataset.py:36: FutureWarning: The error_bad_lines argument has been deprecated and will be removed in a future version. Use on_bad_lines in the future.\n",
      "\n",
      "\n",
      "  df = pd.read_csv(dataset_path, error_bad_lines=False)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "8/8 [==============================] - 130s 15s/step - loss: 0.0716 - binary_accuracy: 0.9770\n",
      "Epoch 2/50\n",
      "8/8 [==============================] - 124s 16s/step - loss: 0.0667 - binary_accuracy: 0.9777\n",
      "Epoch 3/50\n",
      "8/8 [==============================] - 124s 15s/step - loss: 0.0618 - binary_accuracy: 0.9805\n",
      "Epoch 4/50\n",
      "8/8 [==============================] - 133s 16s/step - loss: 0.0549 - binary_accuracy: 0.9828\n",
      "Epoch 5/50\n",
      "8/8 [==============================] - 123s 15s/step - loss: 0.0484 - binary_accuracy: 0.9832\n",
      "Epoch 6/50\n",
      "8/8 [==============================] - 123s 15s/step - loss: 0.0394 - binary_accuracy: 0.9891\n",
      "Epoch 7/50\n",
      "8/8 [==============================] - 123s 15s/step - loss: 0.0359 - binary_accuracy: 0.9883\n",
      "Epoch 8/50\n",
      "8/8 [==============================] - 124s 15s/step - loss: 0.0292 - binary_accuracy: 0.9902\n",
      "Epoch 9/50\n",
      "8/8 [==============================] - 122s 15s/step - loss: 0.0260 - binary_accuracy: 0.9887\n",
      "Epoch 10/50\n",
      "8/8 [==============================] - 126s 16s/step - loss: 0.0228 - binary_accuracy: 0.9902\n",
      "Epoch 11/50\n",
      "8/8 [==============================] - 120s 15s/step - loss: 0.0225 - binary_accuracy: 0.9910\n",
      "Epoch 12/50\n",
      "8/8 [==============================] - 122s 15s/step - loss: 0.0205 - binary_accuracy: 0.9906\n",
      "Epoch 13/50\n",
      "8/8 [==============================] - 120s 15s/step - loss: 0.0199 - binary_accuracy: 0.9906\n",
      "Epoch 14/50\n",
      "8/8 [==============================] - 121s 15s/step - loss: 0.0187 - binary_accuracy: 0.9902\n",
      "Epoch 15/50\n",
      "8/8 [==============================] - 121s 15s/step - loss: 0.0177 - binary_accuracy: 0.9910\n",
      "Epoch 16/50\n",
      "8/8 [==============================] - 125s 16s/step - loss: 0.0175 - binary_accuracy: 0.9902\n",
      "Epoch 17/50\n",
      "8/8 [==============================] - 125s 16s/step - loss: 0.0167 - binary_accuracy: 0.9910\n",
      "Epoch 18/50\n",
      "8/8 [==============================] - 125s 16s/step - loss: 0.0174 - binary_accuracy: 0.9910\n",
      "Epoch 19/50\n",
      "8/8 [==============================] - 125s 16s/step - loss: 0.0157 - binary_accuracy: 0.9910\n",
      "Epoch 20/50\n",
      "8/8 [==============================] - 121s 15s/step - loss: 0.0161 - binary_accuracy: 0.9906\n",
      "Epoch 21/50\n",
      "8/8 [==============================] - 122s 15s/step - loss: 0.0169 - binary_accuracy: 0.9910\n",
      "Epoch 22/50\n",
      "8/8 [==============================] - 122s 15s/step - loss: 0.0161 - binary_accuracy: 0.9910\n",
      "Epoch 23/50\n",
      "8/8 [==============================] - 121s 15s/step - loss: 0.0157 - binary_accuracy: 0.9906\n",
      "Epoch 24/50\n",
      "8/8 [==============================] - 121s 15s/step - loss: 0.0169 - binary_accuracy: 0.9910\n",
      "Epoch 25/50\n",
      "8/8 [==============================] - 124s 16s/step - loss: 0.0149 - binary_accuracy: 0.9906\n",
      "Epoch 26/50\n",
      "8/8 [==============================] - 121s 15s/step - loss: 0.0148 - binary_accuracy: 0.9914\n",
      "Epoch 27/50\n",
      "8/8 [==============================] - 122s 15s/step - loss: 0.0153 - binary_accuracy: 0.9910\n",
      "Epoch 28/50\n",
      "8/8 [==============================] - 121s 15s/step - loss: 0.0158 - binary_accuracy: 0.9910\n",
      "Epoch 29/50\n",
      "8/8 [==============================] - 122s 15s/step - loss: 0.0145 - binary_accuracy: 0.9906\n",
      "Epoch 30/50\n",
      "8/8 [==============================] - 122s 15s/step - loss: 0.0144 - binary_accuracy: 0.9910\n",
      "Epoch 31/50\n",
      "8/8 [==============================] - 126s 16s/step - loss: 0.0149 - binary_accuracy: 0.9910\n",
      "Epoch 32/50\n",
      "8/8 [==============================] - 124s 16s/step - loss: 0.0155 - binary_accuracy: 0.9906\n",
      "Epoch 33/50\n",
      "8/8 [==============================] - 125s 16s/step - loss: 0.0141 - binary_accuracy: 0.9906\n",
      "Epoch 34/50\n",
      "8/8 [==============================] - 123s 15s/step - loss: 0.0141 - binary_accuracy: 0.9906\n",
      "Epoch 35/50\n",
      "8/8 [==============================] - 128s 16s/step - loss: 0.0144 - binary_accuracy: 0.9910\n",
      "Epoch 36/50\n",
      "8/8 [==============================] - 125s 16s/step - loss: 0.0160 - binary_accuracy: 0.9906\n",
      "Epoch 37/50\n",
      "8/8 [==============================] - 124s 15s/step - loss: 0.0147 - binary_accuracy: 0.9914\n",
      "Epoch 38/50\n",
      "8/8 [==============================] - 123s 15s/step - loss: 0.0139 - binary_accuracy: 0.9902\n",
      "Epoch 39/50\n",
      "8/8 [==============================] - 124s 16s/step - loss: 0.0142 - binary_accuracy: 0.9910\n",
      "Epoch 40/50\n",
      "8/8 [==============================] - 134s 17s/step - loss: 0.0147 - binary_accuracy: 0.9918\n",
      "Epoch 41/50\n",
      "8/8 [==============================] - 132s 16s/step - loss: 0.0147 - binary_accuracy: 0.9910\n",
      "Epoch 42/50\n",
      "8/8 [==============================] - 110s 14s/step - loss: 0.0143 - binary_accuracy: 0.9906\n",
      "Epoch 43/50\n",
      "8/8 [==============================] - 126s 16s/step - loss: 0.0138 - binary_accuracy: 0.9910\n",
      "Epoch 44/50\n",
      "8/8 [==============================] - 120s 15s/step - loss: 0.0149 - binary_accuracy: 0.9914\n",
      "Epoch 45/50\n",
      "8/8 [==============================] - 117s 15s/step - loss: 0.0135 - binary_accuracy: 0.9906\n",
      "Epoch 46/50\n",
      "8/8 [==============================] - 128s 16s/step - loss: 0.0138 - binary_accuracy: 0.9910\n",
      "Epoch 47/50\n",
      "8/8 [==============================] - 121s 15s/step - loss: 0.0142 - binary_accuracy: 0.9910\n",
      "Epoch 48/50\n",
      "8/8 [==============================] - 122s 15s/step - loss: 0.0137 - binary_accuracy: 0.9914\n",
      "Epoch 49/50\n",
      "8/8 [==============================] - 124s 15s/step - loss: 0.0139 - binary_accuracy: 0.9906\n",
      "Epoch 50/50\n",
      "8/8 [==============================] - 122s 15s/step - loss: 0.0137 - binary_accuracy: 0.9910\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as DROPOUT_layer_call_fn, DROPOUT_layer_call_and_return_conditional_losses, FINAL_CLASSIFIER_layer_call_fn, FINAL_CLASSIFIER_layer_call_and_return_conditional_losses, DROPOUT_layer_call_fn while saving (showing 5 of 320). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: InquiryEstimatorBERT_Model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: InquiryEstimatorBERT_Model\\assets\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2b821ac19d0>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "savepath = \"InquiryEstimatorBERT_Model\"\n",
    "a,b = get_bert_details()\n",
    "model = get_model_from_file(\"D:\\\\documents\\\\code\\\\Stock\\\\NNS\\\\inquiryProcessor\\\\BERT\\\\InquiryEstimatorBERT_Model\", \n",
    "                            get_ds(32, \"D:\\\\documents\\\\code\\\\Stock\\\\NNS\\\\inquiryProcessor\\\\inquiries_dataset.csv\"), 50)\n",
    "train(savepath=savepath, model=model, epochs=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"inquiry_analyzer_bert_model_3\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " PREPROCESS (KerasLayer)     multiple                  0         \n",
      "                                                                 \n",
      " BERT_ENCODER (KerasLayer)   multiple                  28763649  \n",
      "                                                                 \n",
      " DROPOUT (Dropout)           multiple                  0         \n",
      "                                                                 \n",
      " FINAL_CLASSIFIER (Dense)    multiple                  5130      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 28,768,779\n",
      "Trainable params: 28,768,778\n",
      "Non-trainable params: 1\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "def classify(a: list) -> Tuple[str, np.ndarray]:\n",
    "    for i in a:\n",
    "        assert type(i) == str\n",
    "    result_tensor = model.call(tf.convert_to_tensor(tf.convert_to_tensor(a)))\n",
    "    result_np = result_tensor.numpy()\n",
    "    return classifierstring(result_np.round()), result_np.round()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['CONTACT'], array([[0., 1., 0., 0., 0., 0., 0., 0., 0., 0.]], dtype=float32))"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classify([\"When can I call you?\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.7.0'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.__version__"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "1f716af3f83aa1e776ab5faf5a7bcecc5e1fe6e401a6591d6c367882f206c492"
  },
  "kernelspec": {
   "display_name": "Python 3.9.12 ('Stock')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
